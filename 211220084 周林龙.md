## <center>科研实践-虚拟主播第二阶段技术报告</center>
<p align = right>211220084 周林龙</p>  

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [科研实践-虚拟主播第二阶段技术报告](#center科研实践-虚拟主播第二阶段技术报告center)
  - [1. 实现思路](#1-实现思路)
  - [2. 实现过程](#2-实现过程)
    - [2.1 虚拟主播形象与人设、](#21-虚拟主播形象与人设)
    - [2.2 获取直播间弹幕](#22-获取直播间弹幕)
    - [2.3 获取AI文本回复](#23-获取ai文本回复)
    - [2.4 转换语音回复](#24-转换语音回复)
  - [3. 效果展示](#3-效果展示)

<!-- /code_chunk_output -->

<p style="page-break-after:always;"></p>

### 1. 实现思路
具体虚拟主播的实现分为以下几部分：

- 获取live2D虚拟主播形象并构造其人设
- 获取直播间观众发送的弹幕
- 通过ChatGpt或其他大语言模型输入人设和弹幕，获取AI文本回复
- 通过TTS技术将AI的文本回复转为语音回复
- 根据回复改变虚拟形象的口型和动作等

### 2. 实现过程
#### 2.1 虚拟主播形象与人设

这里我选择使用[B站up 一个ayabe 的live2d模型-简单小白猫](https://www.bilibili.com/video/BV14v4y1p7eR)，导入到VTube Studio后效果如下

图片



#### 2.2 获取直播间弹幕

最初选择按照段鑫宇、韩楚余同学示例中的[B站up澪式烧酒的教程视频](https://www.bilibili.com/video/BV1EM411T7PR/)进行操作，但实操安装配置完Python及相关环境后，运行start.py文件并不能正确将直播间的弹幕获取到终端上，如下图。
![image-20240122151832069](\image\image-20240122151832069.png)

并且获取弹幕并不是一定失败，不改变文件的情况下多次运行中存在成功获取弹幕的可能，但并没有排查出问题，最后看到这个UP使用的是[blivedm: 获取bilibili直播弹幕](https://github.com/xfgryujk/blivedm)的接口，我选择去github获取最新的版本进行直播间弹幕获取的测试，最后可以稳定的获取直播间弹幕，并且可以通过已登陆账号的cookie的SESSDATA来实现登陆，避免无法查看弹幕的用户名。

![image-20240122152125892](\image\image-20240122152125892.png)

![image-20240122152536944](\image\image-20240122152536944.png)

#### 2.3 获取AI文本回复

- **AI模型选择**：这里我选择使用智谱AI的GLM-4模型，接口文档在此处[智谱AI开放平台 (bigmodel.cn)](https://open.bigmodel.cn/dev/api#glm-4)，接口提供了异步调用返回请求id，再根据请求id查询回复结果的方法。（其实我更想用智谱AI的CharacterGLM模型，这个超拟人大模型更适合虚拟主播，但是文档里的示例代码都跑不了）

- **异步处理消息**：blivedm在处理弹幕、礼物等消息时，为了保持处理消息的顺序以及避免因处理消息时过长的异步操作阻塞网络携程（处理消息和网络运行在同一个协程中），将处理消息做为同步函数，所以对于等待AI回复以及后续的转语音等待语音播放完毕，需要使用create_task处理异步操作。

- **上下文语境联系**：获取AI文本回复时，弹幕为一段一段的（如两条先后的弹幕“太阳系有哪些行星”，“最大的是哪个？”），必须联系弹幕上下文语境，才能获取到正确合理的两个回复，否则只会得到独立没有关联的两个问题的回复，我这里选择用`message_list`和`response_list`保存更新最近的若干条问答，与新的弹幕组合在一起对AI进行询问，获取相对合理的回复。(这样做的话，目前的虚拟主播就是个只有7秒钟记忆的主播，可以改进的方法是将每次的问答都进行保存在list中，最后存入文件中)

#### 2.4 转换语音回复并播放

- **语音转换**：使用edge-tts4
- **语音播放**：使用pygame.mixer


#### 2.5 根据回复改变虚拟形象的口型和动作等


### 3. 效果展示
[效果截图]
[视频文件]
[B站视频链接]
